{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Embeddings\n",
    "Experimenting with autoencoder for molecular graph embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ninja\\AppData\\Local\\Temp\\ipykernel_13664\\1866585249.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from tdc.single_pred import ADME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>O=Cc1ccc(Cl)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vinyltoluene</td>\n",
       "      <td>C=Cc1cccc(C)c1</td>\n",
       "      <td>-3.123150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-(3-ethylcyclopentyl)propanoic acid</td>\n",
       "      <td>CCC1CCC(CCC(=O)O)C1</td>\n",
       "      <td>-3.286116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>sarafloxacin</td>\n",
       "      <td>O=C(O)c1cn(-c2ccc(F)cc2)c2cc(N3CCNCC3)c(F)cc2c1=O</td>\n",
       "      <td>-3.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>sparfloxacin</td>\n",
       "      <td>C[C@H]1CN(c2c(F)c(N)c3c(=O)c(C(=O)O)cn(C4CC4)c...</td>\n",
       "      <td>-3.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>sulindac_form_II</td>\n",
       "      <td>CC1=C(CC(=O)O)c2cc(F)ccc2/C1=C/c1ccc(S(C)=O)cc1</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>tetracaine</td>\n",
       "      <td>CCCCNc1ccc(C(=O)OCCN(C)C)cc1</td>\n",
       "      <td>-3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>thymol</td>\n",
       "      <td>Cc1ccc(C(C)C)c(O)c1</td>\n",
       "      <td>-2.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6988 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Drug_ID  \\\n",
       "0                              Benzo[cd]indol-2(1H)-one   \n",
       "1                                  4-chlorobenzaldehyde   \n",
       "2     4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "3                                          vinyltoluene   \n",
       "4                  3-(3-ethylcyclopentyl)propanoic acid   \n",
       "...                                                 ...   \n",
       "6983                                       sarafloxacin   \n",
       "6984                                       sparfloxacin   \n",
       "6985                                   sulindac_form_II   \n",
       "6986                                         tetracaine   \n",
       "6987                                             thymol   \n",
       "\n",
       "                                                   Drug         Y  \n",
       "0                                  O=C1Nc2cccc3cccc1c23 -3.254767  \n",
       "1                                       O=Cc1ccc(Cl)cc1 -2.177078  \n",
       "2     c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO... -4.662065  \n",
       "3                                        C=Cc1cccc(C)c1 -3.123150  \n",
       "4                                   CCC1CCC(CCC(=O)O)C1 -3.286116  \n",
       "...                                                 ...       ...  \n",
       "6983  O=C(O)c1cn(-c2ccc(F)cc2)c2cc(N3CCNCC3)c(F)cc2c1=O -3.130000  \n",
       "6984  C[C@H]1CN(c2c(F)c(N)c3c(=O)c(C(=O)O)cn(C4CC4)c... -3.370000  \n",
       "6985    CC1=C(CC(=O)O)c2cc(F)ccc2/C1=C/c1ccc(S(C)=O)cc1 -4.500000  \n",
       "6986                       CCCCNc1ccc(C(=O)OCCN(C)C)cc1 -3.010000  \n",
       "6987                                Cc1ccc(C(C)C)c(O)c1 -2.190000  \n",
       "\n",
       "[6988 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "from tdc.single_pred import ADME\n",
    "data = ADME(name = 'Solubility_AqSolDB')\n",
    "data = data.get_split()\n",
    "train = data['train']\n",
    "val = data['valid']\n",
    "test = data['test']\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Conversion\n",
    "\n",
    "Tutorial code adapted from Marcus Deblander, Oxford Protein Informatics Group: https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# general tools\n",
    "import numpy as np\n",
    "\n",
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_features(atom, \n",
    "                      use_chirality = True, \n",
    "                      hydrogens_implicit = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
    "    \n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    \n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    \n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    \n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    \n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    \n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    \n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "\n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "                                    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    \n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "\n",
    "    return np.array(atom_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_features(bond, \n",
    "                      use_stereochemistry = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n",
    "    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for (smiles, y_val) in zip(x_smiles, y):\n",
    "        \n",
    "        # convert SMILES to RDKit mol object\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        # get feature dimensions\n",
    "        n_nodes = mol.GetNumAtoms()\n",
    "        n_edges = 2*mol.GetNumBonds()\n",
    "        unrelated_smiles = \"O=O\"\n",
    "        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
    "        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
    "        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
    "\n",
    "        # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "        X = np.zeros((n_nodes, n_node_features))\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            X[atom.GetIdx(), :] = get_atom_features(atom)\n",
    "            \n",
    "        X = torch.tensor(X, dtype = torch.float)\n",
    "        \n",
    "        # construct edge index array E of shape (2, n_edges)\n",
    "        (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "        torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "        torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "        E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "        \n",
    "        # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "        EF = np.zeros((n_edges, n_edge_features))\n",
    "        \n",
    "        for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
    "            \n",
    "            EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j)))\n",
    "        \n",
    "        EF = torch.tensor(EF, dtype = torch.float)\n",
    "        \n",
    "        # construct label tensor\n",
    "        y_tensor = torch.tensor(np.array([y_val]), dtype = torch.float)\n",
    "        \n",
    "        # construct Pytorch Geometric data object and append to data list\n",
    "        data_list.append(Data(x = X, edge_index = E, edge_attr = EF, y = y_tensor))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:28:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:28:59] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 0,  1,  1,  1,  2,  2,  3,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  7,\n",
      "          8,  8,  9,  9, 10, 10, 11, 11, 11, 12, 12, 12],\n",
      "        [ 1,  0,  2, 11,  1,  3,  2,  4, 12,  3,  5,  4,  6,  5,  7,  6,  8, 12,\n",
      "          7,  9,  8, 10,  9, 11,  1, 10, 12,  3,  7, 11]])\n",
      "tensor([[0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor([-3.2548])\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "try_me = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(train['Drug'], train['Y'])\n",
    "print(try_me[0].x)\n",
    "print(try_me[0].edge_index)\n",
    "print(try_me[0].edge_attr)\n",
    "print(try_me[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(try_me[0].x))\n",
    "print(len(try_me[1].x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(try_me[0].edge_index))\n",
    "print(len(try_me[1].edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(try_me[0].edge_attr))\n",
    "print(len(try_me[1].edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "#width of tensor\n",
    "print(len(try_me[0].x[0]))\n",
    "print(len(try_me[1].x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#width of tensor\n",
    "print(len(try_me[0].edge_index[0]))\n",
    "print(len(try_me[1].edge_index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#width of tensor\n",
    "print(len(try_me[0].edge_attr[0]))\n",
    "print(len(try_me[1].edge_attr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 79 79\n"
     ]
    }
   ],
   "source": [
    "print(try_me[0].num_features, try_me[1].num_features, try_me[2].num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Data.__getattr__ of Data(x=[13, 79], edge_index=[2, 30], edge_attr=[30, 10], y=[1])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_me[0].__getattr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__cat_dim__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__inc__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_edge_attr_cls',\n",
       " '_edge_to_layout',\n",
       " '_edges_to_layout',\n",
       " '_get_edge_index',\n",
       " '_get_tensor',\n",
       " '_get_tensor_size',\n",
       " '_multi_get_tensor',\n",
       " '_put_edge_index',\n",
       " '_put_tensor',\n",
       " '_remove_edge_index',\n",
       " '_remove_tensor',\n",
       " '_store',\n",
       " '_tensor_attr_cls',\n",
       " '_to_type',\n",
       " 'apply',\n",
       " 'apply_',\n",
       " 'batch',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contains_isolated_nodes',\n",
       " 'contains_self_loops',\n",
       " 'contiguous',\n",
       " 'coo',\n",
       " 'cpu',\n",
       " 'csc',\n",
       " 'csr',\n",
       " 'cuda',\n",
       " 'debug',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'edge_attr',\n",
       " 'edge_attrs',\n",
       " 'edge_index',\n",
       " 'edge_stores',\n",
       " 'edge_subgraph',\n",
       " 'edge_weight',\n",
       " 'from_dict',\n",
       " 'generate_ids',\n",
       " 'get_all_edge_attrs',\n",
       " 'get_all_tensor_attrs',\n",
       " 'get_edge_index',\n",
       " 'get_tensor',\n",
       " 'get_tensor_size',\n",
       " 'has_isolated_nodes',\n",
       " 'has_self_loops',\n",
       " 'is_coalesced',\n",
       " 'is_cuda',\n",
       " 'is_directed',\n",
       " 'is_edge_attr',\n",
       " 'is_node_attr',\n",
       " 'is_sorted',\n",
       " 'is_undirected',\n",
       " 'keys',\n",
       " 'multi_get_tensor',\n",
       " 'node_attrs',\n",
       " 'node_offsets',\n",
       " 'node_stores',\n",
       " 'num_edge_features',\n",
       " 'num_edge_types',\n",
       " 'num_edges',\n",
       " 'num_faces',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'num_node_types',\n",
       " 'num_nodes',\n",
       " 'pin_memory',\n",
       " 'pos',\n",
       " 'put_edge_index',\n",
       " 'put_tensor',\n",
       " 'record_stream',\n",
       " 'remove_edge_index',\n",
       " 'remove_tensor',\n",
       " 'requires_grad_',\n",
       " 'share_memory_',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'stores',\n",
       " 'stores_as',\n",
       " 'subgraph',\n",
       " 'to',\n",
       " 'to_dict',\n",
       " 'to_heterogeneous',\n",
       " 'to_namedtuple',\n",
       " 'update',\n",
       " 'update_tensor',\n",
       " 'validate',\n",
       " 'view',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(try_me[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Initial Graph Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from the previous OPIG tutorial as well as pytorch geometric tutorial: https://github.com/AntonioLonga/PytorchGeometricTutorial/blob/main/Tutorial6/Tutorial6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch components\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.models import GAE\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:29:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:10] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:10] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[18:29:11] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Data.__getattr__ of Data(x=[13, 79], y=[1], val_pos_edge_index=[2, 0], val_pos_edge_attr=[0, 10], test_pos_edge_index=[2, 1], test_pos_edge_attr=[1, 10], train_pos_edge_index=[2, 28], train_pos_edge_attr=[28, 10], train_neg_adj_mask=[13, 13], val_neg_edge_index=[2, 0], test_neg_edge_index=[2, 1])>\n"
     ]
    }
   ],
   "source": [
    "# AutoEncoder\n",
    "# parameters & data\n",
    "out_channels = 2\n",
    "\n",
    "train_data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(train['Drug'], train['Y'])\n",
    "train_data_list = [train_test_split_edges(i) for i in train_data_list] # split edges for reconstruction loss\n",
    "print(train_data_list[0].__getattr__)\n",
    "train_dataloader = DataLoader(dataset=train_data_list, batch_size=2**7)\n",
    "\n",
    "num_features = train_data_list[0].num_features\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels)) # GAE default decoder is inner dot product\n",
    "\n",
    "# loss fn = GAE built in reconstruction loss (Kipf and Welling, 2016)\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for (k, batch) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        # Compute prediction and loss\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "        loss = model.recon_loss(z, train_pos_edge_index)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Reconstruction-Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 13 but got size 9 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set the model to training mode - important for batch normalization and dropout layers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Unnecessary in this situation but added for best practices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:55\u001b[0m, in \u001b[0;36mCollater.collate_fn\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, OnDiskDataset):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmulti_get(batch))\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:28\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     26\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch_geometric\\data\\batch.py:93\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_list: List[BaseData],\n\u001b[0;32m     83\u001b[0m                    follow_batch: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m                    exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)\n\u001b[0;32m    103\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch_geometric\\data\\collate.py:92\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m     96\u001b[0m     device \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\ninja\\anaconda3\\envs\\chem-learn\\Lib\\site-packages\\torch_geometric\\data\\collate.py:177\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    174\u001b[0m             shape[cat_dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(slices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    175\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;241m*\u001b[39mshape)\n\u001b[1;32m--> 177\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value, slices, incs\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, TensorFrame):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 13 but got size 9 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# move fast and break things\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
